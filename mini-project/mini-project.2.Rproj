---
title: "Untitled"
format: html
editor: visual
---

## 1. Preparing the Data

```{r}
# Save your input data file into your Project directory
fna.data <- "WisconsinCancer.csv"

# Complete the following code to input the data and store as wisc.df
wisc.df <- read.csv(fna.data, row.names=1)
```

```{r}
head(wisc.df)
```

```{r}
# We can use -1 here to remove the first column
wisc.data <- wisc.df[,-1]
```

```{r}
# Create diagnosis vector for later 
diagnosis <- factor(wisc.df$diagnosis)
```

```{r}
dim(wisc.data)
```

```{r}
nrow(wisc.data)
```

> **Q1**. How many observations are in this dataset?
>
> A. There are 569 observations across 30 different variables.

```{r}
malignant_idx <- grep("^M$", wisc.df$diagnosis)
length(malignant_idx)
```

> **Q2**. How many of the observations have a malignant diagnosis?
>
> A. Of the 569 patients, 212 have a malignant diagnosis.

```{r}
mean_data<-names(diagnosis)
mean_columns <- grep("_mean$", mean_data, value = TRUE)
n_mean_columns <- length(mean_columns)
cat("Number of columns ending with _mean:", n_mean_columns, "\n")
```

> **Q3**. How many variables/features in the data are suffixed with `_mean`?
>
> There are 10 columns in the data that end with the suffix \_mean.

# 2. Principal Component Analysis

```{r}
# Check column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)
```

```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp(wisc.data)
```

```{r}
# Look at summary of results
summary(wisc.pr)
```

-   

    > **Q4**. From your results, what proportion of the original variance is captured by the first principal components (PC1)?
    >
    > The proportion of original variance captured in the PC1 is 0.982.

    ```{r}

    ```

    > **Q5**. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
    >
    > It takes till PC2 to describe at least 70% of the original variance in the data.

    > **Q6**. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
    >
    > It takes till PC3 to describe at least 90% of the original variance in the data.

```{r}
biplot(wisc.pr)
```

> **Q7.** What stands out to you about this plot? Is it easy or difficult to understand? Why?
>
> A. This plot is very difficult to understand because all of the data is stacked on each other with very little annotation that makes the data easier to interpret. What stands out to me is how there are definitely better ways to visualize data.

```{r}
# Scatter plot observations by components 1 and 2
plot(wisc.pr$x, col = diagnosis , 
     xlab = "PC1", ylab = "PC2")
```

> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?
>
> A. The data points do not appear to change despite from being different CPs.
>
> ```{r}
> plot(wisc.pr$x, col = diagnosis, 
>      xlab = "PC1", ylab = "PC3")
> ```

```{r}
# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis

# Load the ggplot2 package
library(ggplot2)

# Make a scatter plot colored by diagnosis
ggplot(df) + 
  aes(PC1, PC2, col=diagnosis) + 
  geom_point()
```

## Variance Explained

```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <- pr.var /sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

## Communicating PCA results

> Q9. For the first principal component, what is the component of the loading vector (i.e. `wisc.pr$rotation[,1]`) for the feature `concave.points_mean`? This tells us how much this original feature contributes to the first PC.
>
> A. The component of the loading vector of the feature concave.points_mean is -4.778078e-05.
>
> ```{r}
> dim(wisc.pr$rotation)            
> head(rownames(wisc.pr$rotation)) 
> row_idx <- which(rownames(wisc.pr$rotation) == "concave.points_mean")
> loading_concave <- wisc.pr$rotation[row_idx, 1]
> ```

# 3. Hierarchical clustering

```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled, method = "euclidean")
wisc.hclust <- hclust(data.dist, method="complete")
```

> **Q10**. Using the plot() and abline() functions, what is the height at which the clustering mode

```{r}
plot(wisc.hclust)
abline(h=20, col="red", lty=2)
```

**Selecting number of clusters**

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust,k=4,h=20)
```

```{r}
table(wisc.hclust.clusters, diagnosis)
```

**Using different methods**

> **Q12.** Which method gives your favorite results for the same `data.dist` dataset? Explain your reasoning.
>
> A. I personally like "ward.D2" as well due to the dendrogram coming out the clearest and most digestible to interpret the data. I know that my least favorite of these methods has to be "complete" with its interesting log scale looking dendreogram being unclear and hard to follow along with.
>
> ```{r}
> wisc.hclust <- hclust(data.dist, method="single")
> plot(wisc.hclust)
> abline(h=20, col="red", lty=2)
> ```
>
> ```{r}
> wisc.hclust <- hclust(data.dist, method="average")
> plot(wisc.hclust)
> abline(h=20, col="red", lty=2)
> ```
>
> ```{r}
> wisc.hclust <- hclust(data.dist, method="ward.D2")
> plot(wisc.hclust)
> abline(h=20, col="red", lty=2)
> ```
>
> ```{r}
> wisc.hclust <- hclust(data.dist, method="complete")
> plot(wisc.hclust)
> abline(h=20, col="red", lty=2)
> ```

# 4. Combining methods

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust,k=4)
```

```{r}
table(wisc.hclust.clusters, diagnosis)
```

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

```{r}
table(grps, diagnosis)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
```

```{r}
g <- as.factor(grps)
levels(g)

```

```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
wisc.pr.hclust <- hclust(wisc.pr$x[, 1:7], method="ward.D2")
```

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```
